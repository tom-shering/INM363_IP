{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83f3307-a47d-4432-95d6-ff8e5264416e",
   "metadata": {},
   "source": [
    "<h1>Solar Generation + Seasonal Component as Exogenous Variable</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea50549-9858-48f4-accd-770b6a9a5c6a",
   "metadata": {},
   "source": [
    "<h3>Imports and Data Instantiation</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89aba5a5-a1fe-4448-9c9f-32b2f67f714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Data Manipulation and Miscellaneous:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "from misc_utils import suppress_warnings, print_cuda_memory_usage\n",
    "from collections import defaultdict\n",
    "\n",
    "# Visualisation:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates # Is this still needed? \n",
    "from IPython.display import display\n",
    "\n",
    "# Preprocessing and Statistical Functionality:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "# PyTorch: \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Seasonal Decomposition: \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Testing:\n",
    "import unittest\n",
    "from RNN_tests import TestNormalisation, TestDenormalisation\n",
    "from RNN_tests import TestTimeSeriesSequenceExtraction, TestDataloaderInitialisation\n",
    "\n",
    "# Custom Function and Class Imports: \n",
    "from data_utils import normalise_dataframe, denormalise_data, create_time_sequences_and_targets\n",
    "from data_utils import generate_random_indices\n",
    "from data_utils import calculate_val_loss_trend, calculate_val_loss_std, calculate_forecast_bias\n",
    "from data_utils import calculate_iqr_normalised_mae, calculate_mase\n",
    "from data_utils import take_logs_of_metrics_whilst_preserving_sign\n",
    "from visualisations import plot_losses, plot_forecast_vs_true_values, plot_random_hourly_forecast_periods\n",
    "from visualisations import plot_errors\n",
    "from visualisations import style_dataframe, display_table\n",
    "\n",
    "# Data:\n",
    "df = pd.read_csv(\"total_df_mv.csv\")\n",
    "df = df[[\"time\", \"generation solar\"]] # two brackets to return a df.\n",
    "\n",
    "try:\n",
    "    df[\"pd_datetime\"] = pd.to_datetime(df[\"time\"], utc=True, errors=\"raise\")\n",
    "    df.set_index(\"pd_datetime\", inplace=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error converting to datetime: {e}\")\n",
    "    \n",
    "#exo_columns = [\"avg_temp\", \"avg_humidity\", \"avg_wind_speed\", \"avg_rain_1h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c743968-5b77-4f7e-9d65-f99b2bc4fa71",
   "metadata": {},
   "source": [
    "<h3>Seasonal Decomposition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b08c9a6-8abd-45a2-ae83-226bc56bc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original column length: 35064\n",
      "decomposed column length: 35064\n",
      "\n",
      "\n",
      "                                                time  generation solar  \\\n",
      "pd_datetime                                                              \n",
      "2014-12-31 23:00:00+00:00  2015-01-01 00:00:00+01:00              49.0   \n",
      "2015-01-01 00:00:00+00:00  2015-01-01 01:00:00+01:00              50.0   \n",
      "2015-01-01 01:00:00+00:00  2015-01-01 02:00:00+01:00              50.0   \n",
      "2015-01-01 02:00:00+00:00  2015-01-01 03:00:00+01:00              50.0   \n",
      "2015-01-01 03:00:00+00:00  2015-01-01 04:00:00+01:00              42.0   \n",
      "\n",
      "                           solar_seasonal  \n",
      "pd_datetime                                \n",
      "2014-12-31 23:00:00+00:00    -1189.725439  \n",
      "2015-01-01 00:00:00+00:00    -1211.012183  \n",
      "2015-01-01 01:00:00+00:00    -1232.595160  \n",
      "2015-01-01 02:00:00+00:00    -1252.865465  \n",
      "2015-01-01 03:00:00+00:00    -1274.860942  \n"
     ]
    }
   ],
   "source": [
    "sd_result = seasonal_decompose(df[\"generation solar\"], period=24, model=\"additive\")\n",
    "\n",
    "#Some checks to make sure the data looks as expected:\n",
    "print(f\"\\noriginal column length: {len(df['generation solar'])}\")\n",
    "print(f\"decomposed column length: {len(sd_result.seasonal)}\\n\\n\")\n",
    "#print(sd_result.seasonal.head(24))\n",
    "#print(sd_result.seasonal.tail(24))\n",
    "\n",
    "# Add the seasonal component into the solar_df:\n",
    "df[\"solar_seasonal\"] = sd_result.seasonal\n",
    "\n",
    "# Checking indexes are all equal to make sure rows match:\n",
    "assert all(df[\"time\"].index == df[\"generation solar\"].index)\n",
    "assert all(df[\"time\"].index == df[\"solar_seasonal\"].index)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "series_columns = [\"generation solar\", \"solar_seasonal\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73fdab-68fe-4597-9557-c447e2b914f6",
   "metadata": {},
   "source": [
    "<h3>Batch Size Instantiation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf1d0f3-5387-4dd5-90eb-eeba13a6936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230eff3d-42b7-47e3-8fe6-ce2394f3f9a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Device Initialisation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e732d99f-7322-40be-8f03-90d84dc31120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"\\nGPU is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\nGPU not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0079c-cea8-42c9-b3d8-c9253302ca1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Normalisation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28808876-0231-487b-9e04-b5f2056676ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_normalisation_bounds (RNN_tests.TestNormalisation) ... ok\n",
      "test_returned_columns_are_floats (RNN_tests.TestNormalisation) ... ok\n",
      "test_returned_df_has_same_dimensions (RNN_tests.TestNormalisation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_df, scaler_values = normalise_dataframe(df, series_columns)\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestNormalisation)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780af58a-c1f0-4a48-88be-c9723d3c97ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Feature and Target Setup using a Sliding Window Approach</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0fb3d16-87ce-4ab0-9b31-6c843933c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_array_type (RNN_tests.TestTimeSeriesSequenceExtraction) ... ok\n",
      "test_shapes (RNN_tests.TestTimeSeriesSequenceExtraction) ... ok\n",
      "test_target_extraction (RNN_tests.TestTimeSeriesSequenceExtraction) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 24 \n",
    "\n",
    "# Extracting features, X, and targets, y:\n",
    "X, y = create_time_sequences_and_targets(normalised_df.values, sequence_length)\n",
    "\n",
    "# Testing to ensure data fed into model is as expected: \n",
    "# REF: https://stackoverflow.com/questions/1322575/what-numbers-can-you-pass-as-verbosity-in-running-python-unit-test-suites\n",
    "# Note: For tests to pass, the variable being forecast must be in the first column. \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTimeSeriesSequenceExtraction)\n",
    "suite._tests[0].setUpClass(data=normalised_df.values)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c2f91-346b-49aa-90d3-e03482af6037",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Train, Val, Test Split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae3dc4a-ded5-4d74-9bf5-efa977273c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 17520 | X_val size: 8760 | X_test size: 8760\n",
      "y_train size: 17520 | y_val size: 8760 | y_test size: 8760\n"
     ]
    }
   ],
   "source": [
    "# Split Setup: \n",
    "train_proportion = 0.5\n",
    "val_proportion = 0.25\n",
    "test_proportion = 1 - (train_proportion + val_proportion)\n",
    "\n",
    "#Splitting:\n",
    "train_size = int(train_proportion * len(X))\n",
    "val_size = int(val_proportion * len(X))\n",
    "\n",
    "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
    "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f8675-73ea-4e67-b933-c8ce8f08bbbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Dataloader Instantiation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4c992b-f96f-42b5-b433-13e6986b81b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_test_loader_length (RNN_tests.TestDataloaderInitialisation) ... ok\n",
      "test_train_loader_length (RNN_tests.TestDataloaderInitialisation) ... ok\n",
      "test_val_loader_length (RNN_tests.TestDataloaderInitialisation) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Converting data to PyTorch tensors:\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Creating TensorDatasets:\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Creating DataLoaders:\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "# (I don't want to shuffle sequential data as the order matters)\n",
    "\n",
    "\n",
    "# I get a warning about copying tensors to other tensors in the unit tests, but I am not doing this as\n",
    "# ... they are originally np arrays, and therefore: \n",
    "# REF: https://stackoverflow.com/questions/14463277/how-to-disable-python-warnings\n",
    "with suppress_warnings(UserWarning):\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(TestDataloaderInitialisation)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cae9f8-20d2-40c6-bee7-417e4f813ae4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Training Loop Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6150fdbd-8d73-4f4f-82ce-b9d0045becf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimiser):\n",
    "    \n",
    "    val_loss_best = 10000000\n",
    "    no_improvement_epoch_sequence_length = 0\n",
    "    # This sets the limit for how many epochs the model can go without improving:\n",
    "    early_stopping_limit = 10\n",
    "    early_stop_counter = 0\n",
    "    epoch_counter = 0\n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialising hidden and cell states at the start of training - stateful approach:\n",
    "    h0, c0 = model.init_hidden_and_cell_states(batch_size)\n",
    "    h0, c0 = h0.to(device), c0.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        batch_process_counter = 0\n",
    "\n",
    "        total_epoch_train_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs, (hn, cn) = model(batch_X, h0, c0)\n",
    "            outputs = outputs.squeeze(1) # Removing additional dimension to turn back to vector. \n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_epoch_train_loss += loss.item() # .item() to get the numerical value from the tensor!\n",
    "\n",
    "            # Backward pass and optimisation:\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            # GRADIENT CLIPPING:\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimiser.step()\n",
    "\n",
    "            # Update hidden and cell states for the next iteration:\n",
    "            h0, c0 = hn.detach(), cn.detach()\n",
    "\n",
    "            batch_process_counter += 1\n",
    "\n",
    "        # Batch loss averaging and tracking:\n",
    "        train_losses.append(total_epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Validation evaluation and possible early stopping:\n",
    "        val_loss = evaluate(model, criterion, val_loader, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if val_loss < val_loss_best:\n",
    "            val_loss_best = val_loss\n",
    "            no_improvement_epoch_sequence_length = 0\n",
    "        else:\n",
    "            no_improvement_epoch_sequence_length += 1\n",
    "\n",
    "        if no_improvement_epoch_sequence_length >= early_stopping_limit:\n",
    "            print(f\"Early stopping due to no improvement. {epoch} epochs.\")\n",
    "            early_stop_counter = 1\n",
    "            break\n",
    "\n",
    "        # Back into train mode after evaluating so backpropagation is possible again: \n",
    "        model.train() \n",
    "    \n",
    "    if early_stop_counter == 0:\n",
    "        print(f\"No early stopping.\")\n",
    "    overall_end_time = time.time()\n",
    "\n",
    "    computation_time_mins = (overall_end_time - overall_start_time) / 60\n",
    "    \n",
    "    return train_losses, val_losses, computation_time_mins, epoch_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369361ea-ac2f-4607-ae9d-5e91aff9a7e0",
   "metadata": {},
   "source": [
    "<h3>Evaluation Loop</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d13d4c9-3369-47aa-8fd1-6aa256530098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, val_or_test_loader, device, test_evaluation=False):\n",
    "    model.eval()  \n",
    "    total_loss = 0\n",
    "    \n",
    "    if test_evaluation: \n",
    "        all_true_values = []\n",
    "        all_predicted_values = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for inputs, targets in val_or_test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Stateless evaluation to avoid individual batches altering batch evaluation too much:\n",
    "            h0, c0 = model.init_hidden_and_cell_states(inputs.size(0))\n",
    "            h0, c0 = h0.to(device), c0.to(device)\n",
    "            \n",
    "            outputs, _ = model(inputs, h0, c0)\n",
    "            outputs = outputs.squeeze(1) # Removing extra dimension.\n",
    "            \n",
    "            if test_evaluation:\n",
    "                # REF: https://www.geeksforgeeks.org/append-extend-python/\n",
    "                # Extend adds each element to a list rather than adding the whole argument as one. See ref.\n",
    "                all_true_values.extend(targets.cpu().numpy())\n",
    "                all_predicted_values.extend(outputs.cpu().numpy())\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_mean_loss = total_loss / len(val_or_test_loader)\n",
    "    \n",
    "    if test_evaluation: \n",
    "        return average_mean_loss, all_true_values, all_predicted_values\n",
    "    else: \n",
    "        return average_mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325959d-37c1-4e89-8667-1aac370eee65",
   "metadata": {},
   "source": [
    "<h2>Cross Validation Nested Loops</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19fdae8-16d5-4997-a559-d05f0f3ad763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: lightweight\n",
      "\n",
      "\n",
      "Early stopping due to no improvement. 24 epochs.\n",
      "|| Experiment 12001: (hidden_dim: 100, lr: 0.001, lstm_dropout: 0.2, optimiser: Adam) : MASE 0.52 : Epochs 0 ||\n",
      "Early stopping due to no improvement. 49 epochs.\n",
      "|| Experiment 12002: (hidden_dim: 100, lr: 0.001, lstm_dropout: 0.2, optimiser: RMSProp) : MASE 0.37 : Epochs 0 ||\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_211523/1869719013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# 2. Model training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# 3. Evaluating Model and Denormalising Values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_211523/1198449776.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimiser)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Validation evaluation and possible early stopping:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_211523/289482731.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, val_or_test_loader, device, test_evaluation)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Removing extra dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IP_energy_spain/RNN_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h0, c0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from RNN_models import LightweightOriginal\n",
    "\n",
    "input_dim = 2 # solar generation and seasonal component \n",
    "num_layers = 2\n",
    "final_dropout = 0.1\n",
    "weight_decay = 1e-06\n",
    "#batch_size = 48\n",
    "epochs = 200\n",
    "graph_title_note = \"lightweight_solar_only\"\n",
    "cv_model_name = \"lightweight_solar_only\"\n",
    "\n",
    "# Hyperparameters to change:\n",
    "hidden_dim_values = [100, 200, 400] \n",
    "lr_values = [1e-03, 1e-04]\n",
    "lstm_dropout_values = [0.2, 0.5]\n",
    "optimisers = [\"Adam\", \"RMSProp\"]\n",
    "\n",
    "experiment_results = {}\n",
    "experiment_start_number = 1200\n",
    "experiment_number = experiment_start_number\n",
    "model_print_counter = 1\n",
    "\n",
    "\n",
    "cross_val_start_time = time.time()\n",
    "\n",
    "for hidden_dim in hidden_dim_values:\n",
    "    for lr in lr_values:\n",
    "        for lstm_dropout in lstm_dropout_values:\n",
    "            for optimiser_key in optimisers:\n",
    "                \n",
    "                # 1. Initialising Model:\n",
    "                experiment_number += 1\n",
    "                model = LightweightOriginal(\"lightweight\", input_dim, hidden_dim, num_layers, lstm_dropout, final_dropout)\n",
    "                if model_print_counter == 1:\n",
    "                    print(f\"\\nModel: {model.model_name}\\n\\n\")\n",
    "                    model_print_counter = 0\n",
    "                criterion = nn.MSELoss()\n",
    "                if optimiser_key == \"Adam\":\n",
    "                    optimiser = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                elif optimiser_key == \"RMSProp\":\n",
    "                    optimiser = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                elif optimiser_key == \"SGD\":\n",
    "                    optimiser = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid optimiser. Must be string input; Adam, RMSProp or SGD.\")\n",
    "                    \n",
    "                experiment_name = f\"hidden_dim: {hidden_dim}, lr: {lr}, lstm_dropout: {lstm_dropout}, optimiser: {optimiser_key}\"\n",
    "                experiment_id = f\"hd{hidden_dim}_lr{lr}_drop{lstm_dropout}_opt:{optimiser_key}\"\n",
    "                \n",
    "                # 2. Model training:\n",
    "                train_losses, val_losses, computation_time, epochs_trained = train_model(model, criterion, optimiser)\n",
    "\n",
    "                # 3. Evaluating Model and Denormalising Values:  \n",
    "                test_loss, test_true_values, test_predicted_values = evaluate(model, criterion, test_loader, device, test_evaluation=True)\n",
    "                true_denorm, forecast_denorm = denormalise_data(test_true_values, test_predicted_values, scaler_values, \"generation solar\")\n",
    "            \n",
    "                # 4. Computing Metrics:\n",
    "                iqr_n_mae = calculate_mase(true_denorm, forecast_denorm)\n",
    "                mase = calculate_mase(true_denorm, forecast_denorm)\n",
    "                mse = mean_squared_error(true_denorm, forecast_denorm)\n",
    "                rmse = math.sqrt(mse)\n",
    "                latter_val_gradient = calculate_val_loss_trend(val_losses, 75)\n",
    "                val_loss_stabilisation = calculate_val_loss_std(val_losses, 0.001)\n",
    "                forecast_bias = calculate_forecast_bias(test_predicted_values, test_true_values)\n",
    "                \n",
    "                # 5. Recording Results:\n",
    "                experiment_results[experiment_number] = {\n",
    "                    \"experiment_number\": experiment_number,\n",
    "                    \"experiment_id\": experiment_id,\n",
    "                    \"hidden_dim\": hidden_dim,\n",
    "                    \"lr\": lr,\n",
    "                    \"lstm_dropout\": lstm_dropout,\n",
    "                    \"optimiser\": optimiser_key,\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"val_losses\": val_losses,\n",
    "                    \"true_denorm\": true_denorm,\n",
    "                    \"forecast_denorm\": forecast_denorm,\n",
    "                    \"test_loss\": test_loss, \n",
    "                    \"iqr_n_mae\": iqr_n_mae,\n",
    "                    \"mase\": mase,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"latter_val_gradient\": latter_val_gradient,\n",
    "                    \"val_loss_stabilisation\": val_loss_stabilisation,\n",
    "                    \"forecast_bias\": forecast_bias,\n",
    "                    \"computation_time\": computation_time }\n",
    "                \n",
    "                # 6. Printing Results:\n",
    "                print(f\"|| Experiment {experiment_number}: ({experiment_name}) : MASE {mase:.2f} : Epochs {epochs_trained} ||\")\n",
    "                # print(f\"|| Test Loss: {test_loss}  ||\")\n",
    "                # print(f\"|| IQR Normalised MAE: {iqr_n_mae}  ||\")\n",
    "                # print(f\"|| MASE: {mase}  ||\")\n",
    "                # print(f\"|| RMSE: {rmse}  ||\")\n",
    "                # print(f\"|| Latter Val Gradient: {latter_val_gradient}  ||\")\n",
    "                # print(f\"|| Val Loss Stabilisation: {val_loss_stabilisation}  ||\")\n",
    "                # print(f\"|| Forecast Bias: {forecast_bias}  ||\")\n",
    "                # print(f\"|| Computation Time: {computation_time}  ||\")\n",
    "                # #print_cuda_memory_usage()\n",
    "                # print(\"\\n\")\n",
    "                \n",
    "                # 7. Saving Model:\n",
    "                torch.save(model.state_dict(), f\"saved_models/{experiment_number}_{model.model_name}.pth\")\n",
    "\n",
    "cross_val_end_time = time.time()\n",
    "cross_val_duration = (cross_val_end_time - cross_val_start_time) / 60\n",
    "print(f\"Cross Validation Duration: {cross_val_duration: .2f} minutes.\\n\\n\")\n",
    "\n",
    "\n",
    "# Finding the best experiment for each metric: \n",
    "evaluation_metrics = [\"test_loss\", \"iqr_n_mae\", \"mase\", \"rmse\", \"latter_val_gradient\", \n",
    "                     \"val_loss_stabilisation\", \"forecast_bias\", \"computation_time\"]\n",
    "best_experiments = {}\n",
    "\n",
    "def process_best_experiment(metric, experiment_number, display_metric_name=None, label_prefix=\"Best experiment for\"):\n",
    "    if display_metric_name is None:\n",
    "        display_metric_name = metric\n",
    "    best_experiment = experiment_results[experiment_number]\n",
    "    best_experiments[display_metric_name] = best_experiment\n",
    "    if display_metric_name == \"most_negative_gradient\" or display_metric_name == \"closest_to_zero_gradient\":\n",
    "        print(f\"{label_prefix}: {experiment_number}  :  {best_experiment[metric]}\")\n",
    "    else: \n",
    "        print(f\"{label_prefix} {display_metric_name}: {experiment_number}  :  {best_experiment[metric]}\")\n",
    "\n",
    "for metric in evaluation_metrics:\n",
    "    if metric == \"val_loss_stabilisation\":\n",
    "        best_experiment_number = min(\n",
    "            {k: v for k, v in experiment_results.items() if isinstance(v[metric], (int, float))},\n",
    "            key=lambda k: experiment_results[k][metric]\n",
    "        )\n",
    "        process_best_experiment(metric, best_experiment_number)\n",
    "\n",
    "    elif metric == \"latter_val_gradient\":\n",
    "        # Most negative gradient:\n",
    "        most_negative_gradient_experiment_number = min(\n",
    "            experiment_results, key=lambda k: experiment_results[k][metric]\n",
    "        )\n",
    "        process_best_experiment(metric, most_negative_gradient_experiment_number, \"most_negative_gradient\", label_prefix=\"Fastest gradient descent at final epoch\")\n",
    "\n",
    "        # Gradient closest to zero:\n",
    "        closest_to_zero_gradient_experiment_number = min(\n",
    "            experiment_results, key=lambda k: abs(experiment_results[k][metric])\n",
    "        )\n",
    "        process_best_experiment(metric, closest_to_zero_gradient_experiment_number, \"closest_to_zero_gradient\", label_prefix=\"Lowest gradient at last epoch\")\n",
    "\n",
    "    \n",
    "    elif metric == \"forecast_bias\":\n",
    "        best_experiment_number = min(\n",
    "            experiment_results, key=lambda k: abs(experiment_results[k][metric])\n",
    "        )\n",
    "        process_best_experiment(metric, best_experiment_number)\n",
    "    \n",
    "    else:\n",
    "        best_experiment_number = min(experiment_results, key=lambda k: experiment_results[k][metric])\n",
    "        process_best_experiment(metric, best_experiment_number)\n",
    "\n",
    "    \n",
    "# Finding the three best experiments for normalised mean of test_loss (MSE) and MASE; NMKM:\n",
    "test_loss_values = [experiment_results[exp][\"test_loss\"] for exp in experiment_results]\n",
    "mase_values = [experiment_results[exp][\"mase\"] for exp in experiment_results]\n",
    "\n",
    "test_loss_min, test_loss_max = min(test_loss_values), max(test_loss_values)\n",
    "mase_min, mase_max = min(mase_values), max(mase_values)\n",
    "\n",
    "for experiment in experiment_results:\n",
    "    experiment_results[experiment][\"test_loss_normalised\"] = (experiment_results[experiment][\"test_loss\"] - test_loss_min) / (test_loss_max - test_loss_min)\n",
    "    experiment_results[experiment][\"mase_normalised\"] = (experiment_results[experiment][\"mase\"] - mase_min) / (mase_max - mase_min)\n",
    "    experiment_results[experiment][\"nmkm_score\"] = (experiment_results[experiment][\"test_loss_normalised\"] * 0.5) + (experiment_results[experiment][\"mase_normalised\"] * 0.5)\n",
    "\n",
    "sorted_experiments = sorted(experiment_results, key=lambda k: experiment_results[k][\"nmkm_score\"])\n",
    "best_nmkm_exp = sorted_experiments[0]\n",
    "second_best_nmkm_exp = sorted_experiments[1]\n",
    "third_best_nmkm_exp = sorted_experiments[2]\n",
    "\n",
    "best_experiments[\"best_nmkm\"] = experiment_results[best_nmkm_exp]\n",
    "best_experiments[\"second_best_nmkm\"] = experiment_results[second_best_nmkm_exp]\n",
    "best_experiments[\"third_best_nmkm\"] = experiment_results[third_best_nmkm_exp]\n",
    "\n",
    "print(f\"Best experiment based on nmkm: {best_nmkm_exp}  :  {best_experiments['best_nmkm']['nmkm_score']}\")\n",
    "print(f\"Second best experiment based on nmkm: {second_best_nmkm_exp}  :  {best_experiments['second_best_nmkm']['nmkm_score']}\")\n",
    "print(f\"Third best experiment based on nmkm: {third_best_nmkm_exp}  :  {best_experiments['third_best_nmkm']['nmkm_score']}\")\n",
    "\n",
    "\n",
    "# Displaying the key information on the best models:\n",
    "experiment_hyperparameters = [\"hidden_dim\", \"lr\", \"lstm_dropout\", \"dropout\"]\n",
    "# best experiments_unique_ids:\n",
    "beui = defaultdict(list)\n",
    "\n",
    "def print_experiment_details(experiment_id, metrics_tested):\n",
    "    print(f\"\\n|| Experiment {experiment_id}, best performance for: {metrics_tested}\")\n",
    "    for metric in experiment_hyperparameters + evaluation_metrics:\n",
    "        print(f\"|| {metric}: {experiment_results[experiment_id].get(metric, 'N/A')}  ||\")\n",
    "\n",
    "print(f\"\\n\\n== BEST EXPERIMENTS ==\")\n",
    "\n",
    "for exp_name, exp_data in best_experiments.items():\n",
    "    experiment_num = exp_data[\"experiment_number\"]\n",
    "    beui[experiment_num].append(exp_name)\n",
    "\n",
    "for experiment_id, metrics_tested in beui.items():\n",
    "    print_experiment_details(experiment_id, \", \".join(metrics_tested))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952d993-b54b-4973-913e-4af407789344",
   "metadata": {},
   "source": [
    "<h3>Heatmaps</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08346808-b402-483a-92f9-b6caf237f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\n== Heatmaps ==\\n\")\n",
    "\n",
    "df_hm = pd.DataFrame(columns=[\"hidden_dim\", \"lstm_dropout\", \"optimiser\", \"lr\", \"test_loss\", \"mase\", \"forecast_bias\", \"computation_time\"])\n",
    "\n",
    "for experiment in experiment_results.values():\n",
    "    df_hm = df_hm.append({\n",
    "        \"hidden_dim\": experiment[\"hidden_dim\"],\n",
    "        \"lstm_dropout\": experiment[\"lstm_dropout\"],\n",
    "        \"optimiser\": experiment[\"optimiser\"],\n",
    "        \"lr\": experiment[\"lr\"],\n",
    "        \"test_loss\": experiment[\"test_loss\"],\n",
    "        \"mase\": experiment[\"mase\"],\n",
    "        \"forecast_bias\": experiment[\"forecast_bias\"],\n",
    "        \"computation_time\": experiment[\"computation_time\"]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "unique_optimisers = df_hm[\"optimiser\"].unique()\n",
    "unique_lrs = df_hm[\"lr\"].unique()\n",
    "\n",
    "for metric_name in [\"test_loss\", \"mase\", \"forecast_bias\", \"computation_time\"]:\n",
    "    print(f\"{metric_name}\")\n",
    "\n",
    "    # Setting min and max for colour normalisation:\n",
    "    vmin = df_hm[metric_name].min()\n",
    "    vmax = df_hm[metric_name].max()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=len(unique_optimisers), ncols=len(unique_lrs), figsize=(15, 15))\n",
    "\n",
    "    if len(unique_optimisers) == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    if len(unique_lrs) == 1:\n",
    "        axes = np.expand_dims(axes, axis=1)\n",
    "\n",
    "    for i, optimiser in enumerate(unique_optimisers):\n",
    "        for j, lr in enumerate(unique_lrs):\n",
    "            subset = df_hm[(df_hm[\"optimiser\"] == optimiser) & (df_hm[\"lr\"] == lr)]\n",
    "            \n",
    "            if not subset.empty:\n",
    "                result = subset.pivot(\"hidden_dim\", \"lstm_dropout\", metric_name)\n",
    "                \n",
    "                if metric_name == \"forecast_bias\":\n",
    "                    cmap_choice = \"Spectral\"\n",
    "                else:\n",
    "                    cmap_choice = \"YlOrRd\"\n",
    "                \n",
    "                sns.heatmap(result, annot=result, fmt=\".3f\", cmap=cmap_choice, ax=axes[i, j], vmin=vmin, vmax=vmax)\n",
    "                title = f\"Optimiser: {optimiser}, lr: {lr}\"\n",
    "                axes[i, j].set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da527160-f083-48b4-8227-369d201ddae3",
   "metadata": {},
   "source": [
    "<h3>Plotting Graphs for Best Experiments</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb3055-2cd9-48d1-98d5-d8293efb80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp_ids_list = list(beui.keys()) # id's of all the best experiments saved into a simple list\n",
    "print(f\"Best experiment id's: {best_exp_ids_list}\")\n",
    "\n",
    "for exp_num in best_exp_ids_list:\n",
    "    print(f\"\\n\\n\\nPlots for Experiment {exp_num}\")\n",
    "    experiment_number = experiment_results[exp_num][\"experiment_number\"]\n",
    "    train_losses = experiment_results[exp_num][\"train_losses\"]\n",
    "    val_losses = experiment_results[exp_num][\"val_losses\"]\n",
    "    true_values = experiment_results[exp_num][\"true_denorm\"]\n",
    "    forecast_values = experiment_results[exp_num][\"forecast_denorm\"]\n",
    "    plot_losses(train_losses, val_losses, \"solar gen.\", f\"experiment number: {experiment_number}\")\n",
    "    plot_forecast_vs_true_values(true_values, forecast_values, \"solar gen.\", f\"experiment number: {experiment_number}\")\n",
    "    plot_random_hourly_forecast_periods(true_values, forecast_values, \"solar gen.\", f\"experiment number: {experiment_number}\")\n",
    "    plot_errors(true_values, forecast_values, \"solar gen.\", f\"experiment number: {experiment_number}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3ba76-08e6-4991-8606-32c2127010df",
   "metadata": {},
   "source": [
    "<h3>Storing Results in Dataframes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad42aa-d9f6-4acd-8af2-d0384b5dc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all experiment results to a .csv file: \n",
    "keys_to_extract = [\n",
    "    \"experiment_number\", \"hidden_dim\", \"lr\", \"lstm_dropout\", \"optimiser\", \"test_loss\", \"mase\", \n",
    "    \"latter_val_gradient\", \"val_loss_stabilisation\", \"forecast_bias\", \"computation_time\"]\n",
    "\n",
    "best_experiments_dict_for_export = {\n",
    "    k: {sub_key: experiment_results[k][sub_key] for sub_key in keys_to_extract}\n",
    "    for k in beui if k in experiment_results}\n",
    "\n",
    "all_experiments_dict_for_export = {k: {sub_key: experiment_results[k].get(sub_key, \"N/A\") \n",
    "                                       for sub_key in keys_to_extract} \n",
    "                                   for k in experiment_results}\n",
    "\n",
    "def format_results_to_df(results_dict, best_results=True):\n",
    "    \n",
    "    cross_val_results_df = pd.DataFrame(results_dict).T\n",
    "    if best_results == True:\n",
    "        cross_val_results_df.reset_index(drop=True, inplace=True)\n",
    "    cross_val_results_df.index = range(1, len(cross_val_results_df) + 1)\n",
    "    cross_val_results_df.rename(columns={\n",
    "        \"experiment_number\": \"exp_num\",\n",
    "        \"hidden_dim\": \"hd\", \n",
    "        \"lstm_dropout\": \"drop.\", \n",
    "        \"optimiser\": \"opt.\",\n",
    "        \"val_loss_stabilisation\": \"l.stabil.\",\n",
    "        \"latter_val_gradient\": \"l.grad.\",\n",
    "        \"forecast_bias\": \"bias\", \n",
    "        \"computation_time\": \"time\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    for col in cross_val_results_df.columns:\n",
    "        if col not in (\"exp_num\", \"hd\", \"optimiser\"):\n",
    "            for index, value in cross_val_results_df[col].iteritems():\n",
    "                if value == 0:\n",
    "                    cross_val_results_df.at[index, col] = 0\n",
    "                # The second condition here shouldn't be needed but it is:\n",
    "                elif isinstance(value, str) and col == \"l.stabil.\":\n",
    "                    cross_val_results_df.at[index, col] = \"N/A\"\n",
    "                elif isinstance(value, (int, float)) and col not in (\"lr\", \"drop.\", \"mase\"):\n",
    "                    # REF: https://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python\n",
    "                    #rounded = round(value, 4 - int(np.floor(np.log10(abs(value)))) - 1)\n",
    "                    rounded_value = \"{:.1e}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = rounded_value\n",
    "                elif col == \"bias\":\n",
    "                    formatted_drop = \"{:.1e}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = formatted_drop\n",
    "                elif col == \"mase\":\n",
    "                    formatted_drop = \"{:.2f}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = formatted_drop\n",
    "                elif col == \"drop.\":\n",
    "                    formatted_drop = \"{:.2f}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = formatted_drop\n",
    "                elif col == \"time\":\n",
    "                    formatted_drop = \"{:.2f}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = formatted_drop\n",
    "                elif col == \"lr\":\n",
    "                    formatted_lr = \"{:.1e}\".format(value)\n",
    "                    cross_val_results_df.at[index, col] = formatted_lr\n",
    "    return cross_val_results_df\n",
    "                    \n",
    "best_cv_results_df = format_results_to_df(best_experiments_dict_for_export)\n",
    "all_cv_results_df = format_results_to_df(all_experiments_dict_for_export, best_results=False)\n",
    "           \n",
    "best_cv_results_df.to_csv(f\"best_cv_results_{experiment_start_number}.csv\", index=False)\n",
    "all_cv_results_df.to_csv(f\"all_cv_results_{experiment_start_number}.csv\", index=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "display_table(best_cv_results_df, \"== Best Results ==\")\n",
    "\n",
    "def split_and_assign(df):\n",
    "    sections = list(np.array_split(df, np.ceil(len(df) / 16))) \n",
    "    for i, section in enumerate(sections, start=1):\n",
    "        # REF: https://www.programiz.com/python-programming/methods/built-in/globals\n",
    "        globals()[f\"all_cv_results_df{i}\"] = section\n",
    "\n",
    "split_and_assign(all_cv_results_df)\n",
    "\n",
    "for i in range(1, int(np.ceil(len(all_cv_results_df) / 16)) + 1):\n",
    "    display_table(globals()[f\"all_cv_results_df{i}\"], f\"== All Results {i} ==\")\n",
    "\n",
    "# Storing time series data for best experiments: \n",
    "time_series_columns = [\"train_losses\", \"val_losses\", \"true_denorm\", \"forecast_denorm\"]\n",
    "\n",
    "for experiment_number, experiment_data in experiment_results.items():\n",
    "    if experiment_number not in best_exp_ids_list:\n",
    "        continue\n",
    "    \n",
    "    data = {col: experiment_data[col] for col in time_series_columns if col in experiment_data}\n",
    "    \n",
    "    max_length = max(len(v) for v in data.values())\n",
    "    \n",
    "    for col, values in data.items():\n",
    "        padding_length = max_length - len(values)\n",
    "        if isinstance(values, np.ndarray):\n",
    "            padding = np.full(padding_length, np.nan)\n",
    "            data[col] = np.concatenate([values, padding])\n",
    "        else:\n",
    "            data[col] = values + [None] * padding_length\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    file_path = f\"saved_result_time_series/{cv_model_name}_exp_{experiment_number}.csv\"\n",
    "    df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42175391-1039-455e-a564-17f33458c1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
